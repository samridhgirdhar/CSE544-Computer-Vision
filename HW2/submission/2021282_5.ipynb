{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 PCD files.\n",
      "Loaded selected_pcds/pointcloud_0000.pcd with 22915 points\n",
      "Loaded selected_pcds/pointcloud_0004.pcd with 22904 points\n",
      "\n",
      "Using files for registration:\n",
      "Source: selected_pcds/pointcloud_0000.pcd\n",
      "Target: selected_pcds/pointcloud_0004.pcd\n",
      "\n",
      "Initial transformation matrix:\n",
      "[[ 0.49867657 -0.4728796  -0.72643414 -0.11340157]\n",
      " [ 0.76366363 -0.15677768  0.62628957  0.08745424]\n",
      " [-0.41004822 -0.86706727  0.2829396   0.4715063 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "Initial fitness: 0.0073, Initial RMSE: 0.0334\n",
      "Estimated fitness: 0.0075, Estimated RMSE: 0.0315\n",
      "\n",
      "Estimated transformation matrix:\n",
      "[[ 0.4995302  -0.48161907 -0.72007822 -0.11912481]\n",
      " [ 0.76627663 -0.14207629  0.6266055   0.09296939]\n",
      " [-0.4040912  -0.86478749  0.29808204  0.46852236]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "Saving registration results...\n",
      "Visualization saved to registration_result.png\n",
      "Registration metrics saved to registration_metrics.txt\n",
      "\n",
      "Registration Summary:\n",
      "Initial fitness: 0.0073\n",
      "Initial inlier RMSE: 0.0334\n",
      "Estimated fitness: 0.0075\n",
      "Estimated inlier RMSE: 0.0315\n",
      "Transformed source point cloud saved to results/transformed_source.pcd\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_available_pcds(dataset_path):\n",
    "    \"\"\"Find all available PCD files in the dataset folder and sort them.\"\"\"\n",
    "    pcd_files = glob.glob(os.path.join(dataset_path, \"pointcloud_*.pcd\"))\n",
    "    \n",
    "    \n",
    "    def extract_number(filename):\n",
    "        match = re.search(r'pointcloud_(\\d+)\\.pcd', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    pcd_files.sort(key=extract_number)\n",
    "    \n",
    "    if len(pcd_files) < 2:\n",
    "        raise ValueError(\"Not enough PCD files found in the dataset folder. Need at least 2 files.\")\n",
    "    \n",
    "    print(f\"Found {len(pcd_files)} PCD files.\")\n",
    "    return pcd_files\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Load a point cloud from a PCD file.\"\"\"\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(file_path)\n",
    "        if len(pcd.points) == 0:\n",
    "            print(f\"Warning: {file_path} loaded but contains 0 points\")\n",
    "            return None\n",
    "        print(f\"Loaded {file_path} with {len(pcd.points)} points\")\n",
    "        return pcd\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_consecutive_valid_pcds(pcd_files):\n",
    "    \"\"\"Find two consecutive valid PCD files.\"\"\"\n",
    "    for i in range(len(pcd_files) - 1):\n",
    "        source = load_point_cloud(pcd_files[i])\n",
    "        if source is None or len(source.points) == 0:\n",
    "            continue\n",
    "            \n",
    "        target = load_point_cloud(pcd_files[i+1])\n",
    "        if target is None or len(target.points) == 0:\n",
    "            continue\n",
    "            \n",
    "        return source, target, pcd_files[i], pcd_files[i+1]\n",
    "    \n",
    "    raise ValueError(\"Could not find two consecutive valid PCD files.\")\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.05):\n",
    "    \"\"\"Downsample and compute normals for a point cloud.\"\"\"\n",
    "    \n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    \n",
    "    pcd_down.estimate_normals(\n",
    "        search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    \n",
    "    return pcd_down\n",
    "\n",
    "def prepare_dataset(source_pcd, target_pcd, voxel_size=0.05):\n",
    "    \"\"\"Prepare point cloud data for registration.\"\"\"\n",
    "    source_down = preprocess_point_cloud(source_pcd, voxel_size)\n",
    "    target_down = preprocess_point_cloud(target_pcd, voxel_size)\n",
    "    \n",
    "    return source_down, target_down\n",
    "\n",
    "def execute_point_to_point_icp(source, target, initial_transformation, threshold=0.05, max_iteration=100):\n",
    "    \"\"\"Execute point-to-point ICP registration.\"\"\"\n",
    "    \n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(initial_transformation)\n",
    "    \n",
    "    \n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "        source_transformed, target, threshold, np.identity(4))\n",
    "    initial_fitness = evaluation.fitness\n",
    "    initial_inlier_rmse = evaluation.inlier_rmse\n",
    "    \n",
    "    print(f\"Initial fitness: {initial_fitness:.4f}, Initial RMSE: {initial_inlier_rmse:.4f}\")\n",
    "    \n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, initial_transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iteration)\n",
    "    )\n",
    "    \n",
    "    print(f\"Estimated fitness: {result.fitness:.4f}, Estimated RMSE: {result.inlier_rmse:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'initial_fitness': initial_fitness,\n",
    "        'initial_inlier_rmse': initial_inlier_rmse,\n",
    "        'estimated_fitness': result.fitness,\n",
    "        'estimated_inlier_rmse': result.inlier_rmse,\n",
    "        'transformation_matrix': result.transformation\n",
    "    }\n",
    "\n",
    "def generate_initial_transformation():\n",
    "    \"\"\"Generate a valid initial transformation matrix with rotation and translation.\"\"\"\n",
    "    \n",
    "    R = ortho_group.rvs(3)\n",
    "    \n",
    "    \n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:, 0] = -R[:, 0]  # Flip one column to ensure det = 1\n",
    "    \n",
    "    \n",
    "    t = np.random.uniform(-0.5, 0.5, 3).reshape(3, 1)\n",
    "    \n",
    "    \n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t.flatten()\n",
    "    \n",
    "    return T\n",
    "\n",
    "def save_point_cloud_visualization(source, target, transformation, output_file=\"registration_result.png\"):\n",
    "    \"\"\"Save a visualization of point clouds to a file using matplotlib.\"\"\"\n",
    "    \n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(transformation)\n",
    "    \n",
    "    \n",
    "    source_points = np.asarray(source_transformed.points)\n",
    "    target_points = np.asarray(target.points)\n",
    "    \n",
    "    \n",
    "    max_points = 5000\n",
    "    source_indices = np.random.choice(len(source_points), min(max_points, len(source_points)), replace=False)\n",
    "    target_indices = np.random.choice(len(target_points), min(max_points, len(target_points)), replace=False)\n",
    "    \n",
    "    source_points = source_points[source_indices]\n",
    "    target_points = target_points[target_indices]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    \n",
    "    ax.scatter(source_points[:, 0], source_points[:, 1], source_points[:, 2], c='red', s=1, label='Source (Transformed)')\n",
    "    ax.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Point Cloud Registration Result')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.array([\n",
    "        np.max([source_points[:, 0].max(), target_points[:, 0].max()]) - \n",
    "        np.min([source_points[:, 0].min(), target_points[:, 0].min()]),\n",
    "        np.max([source_points[:, 1].max(), target_points[:, 1].max()]) - \n",
    "        np.min([source_points[:, 1].min(), target_points[:, 1].min()]),\n",
    "        np.max([source_points[:, 2].max(), target_points[:, 2].max()]) - \n",
    "        np.min([source_points[:, 2].min(), target_points[:, 2].min()])\n",
    "    ]).max() / 2.0\n",
    "    \n",
    "    mid_x = (source_points[:, 0].mean() + target_points[:, 0].mean()) / 2\n",
    "    mid_y = (source_points[:, 1].mean() + target_points[:, 1].mean()) / 2\n",
    "    mid_z = (source_points[:, 2].mean() + target_points[:, 2].mean()) / 2\n",
    "    \n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "def save_registration_metrics(result, source_file, target_file, output_file=\"registration_metrics.txt\"):\n",
    "    \"\"\"Save the registration metrics to a text file.\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"Point Cloud Registration Results\\n\")\n",
    "        f.write(\"===============================\\n\\n\")\n",
    "        f.write(f\"Source file: {source_file}\\n\")\n",
    "        f.write(f\"Target file: {target_file}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Initial Transformation Matrix:\\n\")\n",
    "        for row in result['initial_transformation']:\n",
    "            f.write(f\"{row[0]:10.6f} {row[1]:10.6f} {row[2]:10.6f} {row[3]:10.6f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"Estimated Transformation Matrix:\\n\")\n",
    "        for row in result['transformation_matrix']:\n",
    "            f.write(f\"{row[0]:10.6f} {row[1]:10.6f} {row[2]:10.6f} {row[3]:10.6f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"Registration Metrics:\\n\")\n",
    "        f.write(f\"Initial fitness: {result['initial_fitness']:.6f}\\n\")\n",
    "        f.write(f\"Initial inlier RMSE: {result['initial_inlier_rmse']:.6f}\\n\")\n",
    "        f.write(f\"Estimated fitness: {result['estimated_fitness']:.6f}\\n\")\n",
    "        f.write(f\"Estimated inlier RMSE: {result['estimated_inlier_rmse']:.6f}\\n\")\n",
    "    \n",
    "    print(f\"Registration metrics saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    \n",
    "    dataset_path = \"selected_pcds\"  \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        pcd_files = find_available_pcds(dataset_path)\n",
    "        \n",
    "        \n",
    "        source, target, source_file, target_file = find_consecutive_valid_pcds(pcd_files)\n",
    "        \n",
    "        print(f\"\\nUsing files for registration:\")\n",
    "        print(f\"Source: {source_file}\")\n",
    "        print(f\"Target: {target_file}\")\n",
    "        \n",
    "        \n",
    "        source_down, target_down = prepare_dataset(source, target)\n",
    "        \n",
    "        \n",
    "        initial_transformation = generate_initial_transformation()\n",
    "        print(\"\\nInitial transformation matrix:\")\n",
    "        print(initial_transformation)\n",
    "        \n",
    "        \n",
    "        result = execute_point_to_point_icp(source_down, target_down, initial_transformation)\n",
    "        \n",
    "        \n",
    "        result['initial_transformation'] = initial_transformation\n",
    "        \n",
    "        print(\"\\nEstimated transformation matrix:\")\n",
    "        print(result['transformation_matrix'])\n",
    "        \n",
    "        \n",
    "        print(\"\\nSaving registration results...\")\n",
    "        save_point_cloud_visualization(source, target, result['transformation_matrix'])\n",
    "        save_registration_metrics(result, source_file, target_file)\n",
    "        \n",
    "        \n",
    "        print(\"\\nRegistration Summary:\")\n",
    "        print(f\"Initial fitness: {result['initial_fitness']:.4f}\")\n",
    "        print(f\"Initial inlier RMSE: {result['initial_inlier_rmse']:.4f}\")\n",
    "        print(f\"Estimated fitness: {result['estimated_fitness']:.4f}\")\n",
    "        print(f\"Estimated inlier RMSE: {result['estimated_inlier_rmse']:.4f}\")\n",
    "        \n",
    "        \n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        \n",
    "        \n",
    "        source_transformed = copy.deepcopy(source)\n",
    "        source_transformed.transform(result['transformation_matrix'])\n",
    "        output_pcd_path = os.path.join(\"results\", \"transformed_source.pcd\")\n",
    "        o3d.io.write_point_cloud(output_pcd_path, source_transformed)\n",
    "        print(f\"Transformed source point cloud saved to {output_pcd_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 PCD files.\n",
      "Loaded selected_pcds/pointcloud_0000.pcd with 22915 points\n",
      "Loaded selected_pcds/pointcloud_0004.pcd with 22904 points\n",
      "\n",
      "Using files for registration:\n",
      "Source: selected_pcds/pointcloud_0000.pcd\n",
      "Target: selected_pcds/pointcloud_0004.pcd\n",
      "RANSAC initialization is not available: registration_ransac_based_on_feature_matching(): incompatible function arguments. The following argument types are supported:\n",
      "    1. (source: open3d.cuda.pybind.geometry.PointCloud, target: open3d.cuda.pybind.geometry.PointCloud, source_feature: open3d.cuda.pybind.pipelines.registration.Feature, target_feature: open3d.cuda.pybind.pipelines.registration.Feature, mutual_filter: bool, max_correspondence_distance: float, estimation_method: open3d.cuda.pybind.pipelines.registration.TransformationEstimation = TransformationEstimationPointToPoint(with_scaling=False), ransac_n: int = 3, checkers: list[open3d.cuda.pybind.pipelines.registration.CorrespondenceChecker] = [], criteria: open3d.cuda.pybind.pipelines.registration.RANSACConvergenceCriteria = RANSACConvergenceCriteria(max_iteration=100000, confidence=9.990000e-01)) -> open3d.cuda.pybind.pipelines.registration.RegistrationResult\n",
      "\n",
      "Invoked with: PointCloud with 9750 points., PointCloud with 9752 points., Feature class with dimension = 33 and num = 9750\n",
      "Access its data via data member., Feature class with dimension = 33 and num = 9752\n",
      "Access its data via data member., 0.07500000000000001, TransformationEstimationPointToPoint(with_scaling=False), 4, [CorrespondenceCheckerBasedOnEdgeLength with similarity_threshold=0.900000, CorrespondenceCheckerBasedOnDistance with distance_threshold=0.075000], RANSACConvergenceCriteria(max_iteration=4000000, confidence=1.000000e+00)\n",
      "\n",
      "Running experiment: baseline\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.05, 'max_iteration': 100, 'save_visualization': True}\n",
      "Visualization saved to experiment_results/baseline_result.png\n",
      "Experiment completed: baseline\n",
      "Initial fitness: 0.0023, Initial RMSE: 0.0397\n",
      "Estimated fitness: 0.0059, Estimated RMSE: 0.0327\n",
      "Transformation error: 0.1336\n",
      "Runtime: 0.0599 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: high_threshold\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.1, 'max_iteration': 100}\n",
      "Experiment completed: high_threshold\n",
      "Initial fitness: 0.0187, Initial RMSE: 0.0646\n",
      "Estimated fitness: 0.0226, Estimated RMSE: 0.0571\n",
      "Transformation error: 0.1714\n",
      "Runtime: 0.0804 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: low_threshold\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.02, 'max_iteration': 100}\n",
      "Experiment completed: low_threshold\n",
      "Initial fitness: 0.0018, Initial RMSE: 0.0145\n",
      "Estimated fitness: 0.0019, Estimated RMSE: 0.0139\n",
      "Transformation error: 0.0139\n",
      "Runtime: 0.0607 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: high_resolution\n",
      "Configuration: {'voxel_size': 0.02, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.05, 'max_iteration': 100}\n",
      "Experiment completed: high_resolution\n",
      "Initial fitness: 0.0033, Initial RMSE: 0.0350\n",
      "Estimated fitness: 0.0067, Estimated RMSE: 0.0331\n",
      "Transformation error: 0.2323\n",
      "Runtime: 0.1701 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: low_resolution\n",
      "Configuration: {'voxel_size': 0.1, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.05, 'max_iteration': 100}\n",
      "Experiment completed: low_resolution\n",
      "Initial fitness: 0.0028, Initial RMSE: 0.0370\n",
      "Estimated fitness: 0.0036, Estimated RMSE: 0.0365\n",
      "Transformation error: 0.0235\n",
      "Runtime: 0.0140 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: more_iterations\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'random', 'icp_method': 'point_to_point', 'threshold': 0.05, 'max_iteration': 200}\n",
      "Experiment completed: more_iterations\n",
      "Initial fitness: 0.0023, Initial RMSE: 0.0400\n",
      "Estimated fitness: 0.0036, Estimated RMSE: 0.0354\n",
      "Transformation error: 0.1234\n",
      "Runtime: 0.1135 seconds, Iterations: 200\n",
      "\n",
      "Running experiment: point_to_plane\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'random', 'icp_method': 'point_to_plane', 'threshold': 0.05, 'max_iteration': 100, 'save_visualization': True}\n",
      "Visualization saved to experiment_results/point_to_plane_result.png\n",
      "Experiment completed: point_to_plane\n",
      "Initial fitness: 0.0083, Initial RMSE: 0.0345\n",
      "Estimated fitness: 0.0094, Estimated RMSE: 0.0340\n",
      "Transformation error: 0.3378\n",
      "Runtime: 0.1826 seconds, Iterations: 100\n",
      "\n",
      "Running experiment: identity_init\n",
      "Configuration: {'voxel_size': 0.05, 'init_method': 'identity', 'icp_method': 'point_to_point', 'threshold': 0.05, 'max_iteration': 100}\n",
      "Experiment completed: identity_init\n",
      "Initial fitness: 0.9674, Initial RMSE: 0.0179\n",
      "Estimated fitness: 0.9677, Estimated RMSE: 0.0176\n",
      "Transformation error: 0.0045\n",
      "Runtime: 0.0927 seconds, Iterations: 100\n",
      "\n",
      "All experiment results saved to experiment_results\n",
      "Best experiment: low_threshold with RMSE: 0.013856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Init Method</th>\n",
       "      <th>ICP Method</th>\n",
       "      <th>Voxel Size</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Initial Fitness</th>\n",
       "      <th>Initial RMSE</th>\n",
       "      <th>Final Fitness</th>\n",
       "      <th>Final RMSE</th>\n",
       "      <th>Transform Error</th>\n",
       "      <th>Rotation Error</th>\n",
       "      <th>Translation Error</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Runtime (s)</th>\n",
       "      <th>Converged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>low_threshold</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.009166</td>\n",
       "      <td>100</td>\n",
       "      <td>0.060709</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>identity_init</td>\n",
       "      <td>identity</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.967385</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>100</td>\n",
       "      <td>0.092742</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.039704</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.032716</td>\n",
       "      <td>0.133555</td>\n",
       "      <td>0.102531</td>\n",
       "      <td>0.085582</td>\n",
       "      <td>100</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_resolution</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.034967</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.033124</td>\n",
       "      <td>0.232253</td>\n",
       "      <td>0.222972</td>\n",
       "      <td>0.064999</td>\n",
       "      <td>100</td>\n",
       "      <td>0.170080</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>point_to_plane</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_plane</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.033999</td>\n",
       "      <td>0.337830</td>\n",
       "      <td>0.205527</td>\n",
       "      <td>0.268119</td>\n",
       "      <td>100</td>\n",
       "      <td>0.182559</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>more_iterations</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.123398</td>\n",
       "      <td>0.118738</td>\n",
       "      <td>0.033591</td>\n",
       "      <td>200</td>\n",
       "      <td>0.113508</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>low_resolution</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.037036</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.036469</td>\n",
       "      <td>0.023501</td>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>100</td>\n",
       "      <td>0.014012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_threshold</td>\n",
       "      <td>random</td>\n",
       "      <td>point_to_point</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.064613</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.057116</td>\n",
       "      <td>0.171422</td>\n",
       "      <td>0.131764</td>\n",
       "      <td>0.109653</td>\n",
       "      <td>100</td>\n",
       "      <td>0.080399</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Experiment Init Method      ICP Method  Voxel Size  Threshold  \\\n",
       "2    low_threshold      random  point_to_point        0.05       0.02   \n",
       "7    identity_init    identity  point_to_point        0.05       0.05   \n",
       "0         baseline      random  point_to_point        0.05       0.05   \n",
       "3  high_resolution      random  point_to_point        0.02       0.05   \n",
       "6   point_to_plane      random  point_to_plane        0.05       0.05   \n",
       "5  more_iterations      random  point_to_point        0.05       0.05   \n",
       "4   low_resolution      random  point_to_point        0.10       0.05   \n",
       "1   high_threshold      random  point_to_point        0.05       0.10   \n",
       "\n",
       "   Initial Fitness  Initial RMSE  Final Fitness  Final RMSE  Transform Error  \\\n",
       "2         0.001846      0.014531       0.001949    0.013856         0.013867   \n",
       "7         0.967385      0.017939       0.967692    0.017643         0.004531   \n",
       "0         0.002256      0.039704       0.005949    0.032716         0.133555   \n",
       "3         0.003326      0.034967       0.006651    0.033124         0.232253   \n",
       "6         0.008308      0.034478       0.009436    0.033999         0.337830   \n",
       "5         0.002256      0.040000       0.003590    0.035364         0.123398   \n",
       "4         0.002848      0.037036       0.003607    0.036469         0.023501   \n",
       "1         0.018667      0.064613       0.022564    0.057116         0.171422   \n",
       "\n",
       "   Rotation Error  Translation Error  Iterations  Runtime (s)  Converged  \n",
       "2        0.010405           0.009166         100     0.060709      False  \n",
       "7        0.000220           0.004526         100     0.092742      False  \n",
       "0        0.102531           0.085582         100     0.059861      False  \n",
       "3        0.222972           0.064999         100     0.170080      False  \n",
       "6        0.205527           0.268119         100     0.182559      False  \n",
       "5        0.118738           0.033591         200     0.113508      False  \n",
       "4        0.017971           0.015144         100     0.014012      False  \n",
       "1        0.131764           0.109653         100     0.080399      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All visualizations created successfully!\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def find_available_pcds(dataset_path):\n",
    "    \"\"\"Find all available PCD files in the dataset folder and sort them.\"\"\"\n",
    "    pcd_files = glob.glob(os.path.join(dataset_path, \"pointcloud_*.pcd\"))\n",
    "    \n",
    "    \n",
    "    def extract_number(filename):\n",
    "        match = re.search(r'pointcloud_(\\d+)\\.pcd', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    pcd_files.sort(key=extract_number)\n",
    "    \n",
    "    if len(pcd_files) < 2:\n",
    "        raise ValueError(\"Not enough PCD files found in the dataset folder. Need at least 2 files.\")\n",
    "    \n",
    "    print(f\"Found {len(pcd_files)} PCD files.\")\n",
    "    return pcd_files\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Load a point cloud from a PCD file.\"\"\"\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(file_path)\n",
    "        if len(pcd.points) == 0:\n",
    "            print(f\"Warning: {file_path} loaded but contains 0 points\")\n",
    "            return None\n",
    "        print(f\"Loaded {file_path} with {len(pcd.points)} points\")\n",
    "        return pcd\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_consecutive_valid_pcds(pcd_files, index=0):\n",
    "    \"\"\"Find two consecutive valid PCD files starting from the given index.\"\"\"\n",
    "    if index >= len(pcd_files) - 1:\n",
    "        raise ValueError(\"Index too large, not enough PCD files available.\")\n",
    "        \n",
    "    source = load_point_cloud(pcd_files[index])\n",
    "    if source is None or len(source.points) == 0:\n",
    "        return find_consecutive_valid_pcds(pcd_files, index + 1)\n",
    "        \n",
    "    target = load_point_cloud(pcd_files[index + 1])\n",
    "    if target is None or len(target.points) == 0:\n",
    "        return find_consecutive_valid_pcds(pcd_files, index + 1)\n",
    "        \n",
    "    return source, target, pcd_files[index], pcd_files[index + 1]\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.05, compute_normals=True):\n",
    "    \"\"\"Downsample and compute normals for a point cloud.\"\"\"\n",
    "    \n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    \n",
    "    if compute_normals:\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    \n",
    "    return pcd_down\n",
    "\n",
    "def prepare_dataset(source_pcd, target_pcd, voxel_size=0.05, compute_normals=True):\n",
    "    \"\"\"Prepare point cloud data for registration.\"\"\"\n",
    "    source_down = preprocess_point_cloud(source_pcd, voxel_size, compute_normals)\n",
    "    target_down = preprocess_point_cloud(target_pcd, voxel_size, compute_normals)\n",
    "    \n",
    "    return source_down, target_down\n",
    "\n",
    "def generate_random_transformation():\n",
    "    \"\"\"Generate a valid initial transformation matrix with rotation and translation.\"\"\"\n",
    "    \n",
    "    R = ortho_group.rvs(3)\n",
    "    \n",
    "    \n",
    "    if np.linalg.det(R) < 0:\n",
    "        \n",
    "    \n",
    "    \n",
    "    t = np.random.uniform(-0.5, 0.5, 3).reshape(3, 1)\n",
    "    \n",
    "    \n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t.flatten()\n",
    "    \n",
    "    return T\n",
    "\n",
    "def get_initial_transformation(method=\"random\", source=None, target=None, voxel_size=0.05):\n",
    "    \"\"\"Get initial transformation based on specified method.\"\"\"\n",
    "    if method == \"random\":\n",
    "        return generate_random_transformation()\n",
    "    elif method == \"identity\":\n",
    "        return np.eye(4)\n",
    "    elif method == \"ransac\":\n",
    "        # Use RANSAC for global registration\n",
    "        if source is None or target is None:\n",
    "            raise ValueError(\"Source and target point clouds are required for RANSAC initialization\")\n",
    "        \n",
    "        # Prepare FPFH feature descriptors\n",
    "        source_fpfh = compute_fpfh_features(source, voxel_size)\n",
    "        target_fpfh = compute_fpfh_features(target, voxel_size)\n",
    "        \n",
    "        \n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source, target, source_fpfh, target_fpfh, distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,  # Number of points to use for RANSAC\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result.transformation\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization method: {method}\")\n",
    "\n",
    "def compute_fpfh_features(pcd, voxel_size):\n",
    "    \"\"\"Compute FPFH features for a point cloud.\"\"\"\n",
    "    radius_normal = voxel_size * 2\n",
    "    radius_feature = voxel_size * 5\n",
    "    \n",
    "    # Ensure normals are computed\n",
    "    if not pcd.has_normals():\n",
    "        pcd.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    \n",
    "    # Compute FPFH features\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    \n",
    "    return fpfh\n",
    "\n",
    "def execute_icp(source, target, initial_transformation, icp_method=\"point_to_point\", \n",
    "                threshold=0.05, max_iteration=100, relative_fitness=1e-6, \n",
    "                relative_rmse=1e-6):\n",
    "    \"\"\"Execute ICP registration with specified parameters.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(initial_transformation)\n",
    "    \n",
    "    # Initial evaluation\n",
    "    evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "        source_transformed, target, threshold, np.identity(4))\n",
    "    initial_fitness = evaluation.fitness\n",
    "    initial_inlier_rmse = evaluation.inlier_rmse\n",
    "    \n",
    "    # Set up ICP method\n",
    "    if icp_method == \"point_to_point\":\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    elif icp_method == \"point_to_plane\":\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ICP method: {icp_method}\")\n",
    "    \n",
    "    # Execute ICP\n",
    "    criteria = o3d.pipelines.registration.ICPConvergenceCriteria(\n",
    "        max_iteration=max_iteration,\n",
    "        relative_fitness=relative_fitness,\n",
    "        relative_rmse=relative_rmse\n",
    "    )\n",
    "    \n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, initial_transformation,\n",
    "        estimation, criteria\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    \n",
    "    diff_matrix = np.linalg.inv(initial_transformation) @ result.transformation\n",
    "    \n",
    "    R_diff = diff_matrix[:3, :3]\n",
    "    \n",
    "    rotation_error = np.linalg.norm(R_diff - np.eye(3), 'fro')\n",
    "    \n",
    "    translation_error = np.linalg.norm(diff_matrix[:3, 3])\n",
    "    \n",
    "    transformation_error = np.linalg.norm(diff_matrix - np.eye(4), 'fro')\n",
    "    \n",
    "    \n",
    "    iterations_used = getattr(result, \"iteration\", max_iteration)\n",
    "    \n",
    "    return {\n",
    "        'initial_fitness': initial_fitness,\n",
    "        'initial_inlier_rmse': initial_inlier_rmse,\n",
    "        'estimated_fitness': result.fitness,\n",
    "        'estimated_inlier_rmse': result.inlier_rmse,\n",
    "        'transformation_matrix': result.transformation,\n",
    "        'transformation_error': transformation_error,\n",
    "        'rotation_error': rotation_error,\n",
    "        'translation_error': translation_error,\n",
    "        'runtime': end_time - start_time,\n",
    "        'iterations': iterations_used,\n",
    "        'convergence': iterations_used < max_iteration\n",
    "    }\n",
    "\n",
    "def visualize_registration_result(source, target, transformation, output_file=\"registration_result.png\"):\n",
    "    \"\"\"Visualize registration result and save to file.\"\"\"\n",
    "    \n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(transformation)\n",
    "    \n",
    "    \n",
    "    save_point_cloud_visualization(source, target, transformation, output_file)\n",
    "\n",
    "def save_point_cloud_visualization(source, target, transformation, output_file=\"registration_result.png\"):\n",
    "    \"\"\"Save a visualization of point clouds to a file using matplotlib.\"\"\"\n",
    "    \n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(transformation)\n",
    "    \n",
    "    \n",
    "    source_points = np.asarray(source_transformed.points)\n",
    "    target_points = np.asarray(target.points)\n",
    "    \n",
    "    # Sample points if there are too many (for visualization performance)\n",
    "    max_points = 5000\n",
    "    source_indices = np.random.choice(len(source_points), min(max_points, len(source_points)), replace=False)\n",
    "    target_indices = np.random.choice(len(target_points), min(max_points, len(target_points)), replace=False)\n",
    "    \n",
    "    source_points = source_points[source_indices]\n",
    "    target_points = target_points[target_indices]\n",
    "    \n",
    "    # Create 3D plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot points\n",
    "    ax.scatter(source_points[:, 0], source_points[:, 1], source_points[:, 2], c='red', s=1, label='Source (Transformed)')\n",
    "    ax.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Point Cloud Registration Result')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Set equal aspect ratio\n",
    "    max_range = np.array([\n",
    "        np.max([source_points[:, 0].max(), target_points[:, 0].max()]) - \n",
    "        np.min([source_points[:, 0].min(), target_points[:, 0].min()]),\n",
    "        np.max([source_points[:, 1].max(), target_points[:, 1].max()]) - \n",
    "        np.min([source_points[:, 1].min(), target_points[:, 1].min()]),\n",
    "        np.max([source_points[:, 2].max(), target_points[:, 2].max()]) - \n",
    "        np.min([source_points[:, 2].min(), target_points[:, 2].min()])\n",
    "    ]).max() / 2.0\n",
    "    \n",
    "    mid_x = (source_points[:, 0].mean() + target_points[:, 0].mean()) / 2\n",
    "    mid_y = (source_points[:, 1].mean() + target_points[:, 1].mean()) / 2\n",
    "    mid_z = (source_points[:, 2].mean() + target_points[:, 2].mean()) / 2\n",
    "    \n",
    "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
    "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
    "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "\n",
    "def run_experiment(source, target, experiment_config, experiment_name):\n",
    "    \"\"\"Run a single experiment with the given configuration.\"\"\"\n",
    "    print(f\"\\nRunning experiment: {experiment_name}\")\n",
    "    print(f\"Configuration: {experiment_config}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    voxel_size = experiment_config.get('voxel_size', 0.05)\n",
    "    compute_normals = experiment_config.get('icp_method', 'point_to_point') == 'point_to_plane'\n",
    "    source_down, target_down = prepare_dataset(source, target, voxel_size, compute_normals)\n",
    "    \n",
    "    # Get initial transformation\n",
    "    init_method = experiment_config.get('init_method', 'random')\n",
    "    initial_transformation = get_initial_transformation(\n",
    "        init_method, source_down, target_down, voxel_size\n",
    "    )\n",
    "    \n",
    "    # Execute ICP\n",
    "    result = execute_icp(\n",
    "        source_down, \n",
    "        target_down, \n",
    "        initial_transformation,\n",
    "        icp_method=experiment_config.get('icp_method', 'point_to_point'),\n",
    "        threshold=experiment_config.get('threshold', 0.05),\n",
    "        max_iteration=experiment_config.get('max_iteration', 100),\n",
    "        relative_fitness=experiment_config.get('relative_fitness', 1e-6),\n",
    "        relative_rmse=experiment_config.get('relative_rmse', 1e-6)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    result['experiment_name'] = experiment_name\n",
    "    result['initial_transformation'] = initial_transformation\n",
    "    result['voxel_size'] = voxel_size\n",
    "    result['icp_method'] = experiment_config.get('icp_method', 'point_to_point')\n",
    "    result['threshold'] = experiment_config.get('threshold', 0.05)\n",
    "    result['init_method'] = init_method\n",
    "    \n",
    "    # Save visualization for this experiment if requested\n",
    "    if experiment_config.get('save_visualization', False):\n",
    "        output_dir = \"experiment_results\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        visualize_registration_result(\n",
    "            source, \n",
    "            target, \n",
    "            result['transformation_matrix'],\n",
    "            os.path.join(output_dir, f\"{experiment_name}_result.png\")\n",
    "        )\n",
    "    \n",
    "    print(f\"Experiment completed: {experiment_name}\")\n",
    "    print(f\"Initial fitness: {result['initial_fitness']:.4f}, Initial RMSE: {result['initial_inlier_rmse']:.4f}\")\n",
    "    print(f\"Estimated fitness: {result['estimated_fitness']:.4f}, Estimated RMSE: {result['estimated_inlier_rmse']:.4f}\")\n",
    "    print(f\"Transformation error: {result['transformation_error']:.4f}\")\n",
    "    print(f\"Runtime: {result['runtime']:.4f} seconds, Iterations: {result['iterations']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def format_transformation_matrix(matrix):\n",
    "    \"\"\"Format transformation matrix as a string for display.\"\"\"\n",
    "    result = \"\"\n",
    "    for row in matrix:\n",
    "        result += \"[\" + \" \".join([f\"{val:8.5f}\" for val in row]) + \"]\\n\"\n",
    "    return result\n",
    "\n",
    "def run_multiple_experiments(source, target, source_file, target_file):\n",
    "    \"\"\"Run multiple experiments with different hyperparameter settings.\"\"\"\n",
    "    # Define experiment configurations\n",
    "    experiments = {\n",
    "        \"baseline\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100,\n",
    "            \"save_visualization\": True\n",
    "        },\n",
    "        \"high_threshold\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.1,\n",
    "            \"max_iteration\": 100\n",
    "        },\n",
    "        \"low_threshold\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.02,\n",
    "            \"max_iteration\": 100\n",
    "        },\n",
    "        \"high_resolution\": {\n",
    "            \"voxel_size\": 0.02,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100\n",
    "        },\n",
    "        \"low_resolution\": {\n",
    "            \"voxel_size\": 0.1,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100\n",
    "        },\n",
    "        \"more_iterations\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 200\n",
    "        },\n",
    "        \"point_to_plane\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"random\",\n",
    "            \"icp_method\": \"point_to_plane\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100,\n",
    "            \"save_visualization\": True\n",
    "        },\n",
    "        \"identity_init\": {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"identity\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        source_down, target_down = prepare_dataset(source, target, 0.05, True)\n",
    "        _ = get_initial_transformation(\"ransac\", source_down, target_down, 0.05)\n",
    "        # If we get here, RANSAC works, so add the experiment\n",
    "        experiments[\"ransac_init\"] = {\n",
    "            \"voxel_size\": 0.05,\n",
    "            \"init_method\": \"ransac\",\n",
    "            \"icp_method\": \"point_to_point\",\n",
    "            \"threshold\": 0.05,\n",
    "            \"max_iteration\": 100,\n",
    "            \"save_visualization\": True\n",
    "        }\n",
    "        print(\"RANSAC initialization is available.\")\n",
    "    except Exception as e:\n",
    "        print(f\"RANSAC initialization is not available: {e}\")\n",
    "    \n",
    "    # Run all experiments\n",
    "    results = []\n",
    "    for name, config in experiments.items():\n",
    "        try:\n",
    "            result = run_experiment(source, target, config, name)\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in experiment {name}: {e}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"experiment_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save all results to CSV\n",
    "    results_df = pd.DataFrame([\n",
    "        {\n",
    "            'Experiment': r['experiment_name'],\n",
    "            'Init Method': r['init_method'],\n",
    "            'ICP Method': r['icp_method'],\n",
    "            'Voxel Size': r['voxel_size'],\n",
    "            'Threshold': r['threshold'],\n",
    "            'Initial Fitness': r['initial_fitness'],\n",
    "            'Initial RMSE': r['initial_inlier_rmse'],\n",
    "            'Final Fitness': r['estimated_fitness'],\n",
    "            'Final RMSE': r['estimated_inlier_rmse'],\n",
    "            'Transform Error': r['transformation_error'],\n",
    "            'Rotation Error': r['rotation_error'],\n",
    "            'Translation Error': r['translation_error'],\n",
    "            'Iterations': r['iterations'],\n",
    "            'Runtime (s)': r['runtime'],\n",
    "            'Converged': r['convergence']\n",
    "        }\n",
    "        for r in results\n",
    "    ])\n",
    "    \n",
    "    # Sort by Final RMSE (ascending)\n",
    "    results_df = results_df.sort_values('Final RMSE')\n",
    "    \n",
    "    # Save detailed results and summary\n",
    "    results_df.to_csv(os.path.join(output_dir, \"experiment_results.csv\"), index=False)\n",
    "    \n",
    "    # Generate summary report\n",
    "    best_result = results_df.iloc[0]\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"experiment_summary.txt\"), 'w') as f:\n",
    "        f.write(\"Point Cloud Registration Experiments Summary\\n\")\n",
    "        f.write(\"===========================================\\n\\n\")\n",
    "        f.write(f\"Source file: {source_file}\\n\")\n",
    "        f.write(f\"Target file: {target_file}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Results Table (sorted by Final RMSE):\\n\")\n",
    "        f.write(results_df.to_string(index=False))\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"Best Experiment Configuration:\\n\")\n",
    "        f.write(f\"Experiment: {best_result['Experiment']}\\n\")\n",
    "        f.write(f\"Initialization Method: {best_result['Init Method']}\\n\")\n",
    "        f.write(f\"ICP Method: {best_result['ICP Method']}\\n\")\n",
    "        f.write(f\"Voxel Size: {best_result['Voxel Size']}\\n\")\n",
    "        f.write(f\"Threshold: {best_result['Threshold']}\\n\")\n",
    "        f.write(f\"Iterations: {best_result['Iterations']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"Best Experiment Results:\\n\")\n",
    "        f.write(f\"Initial Fitness: {best_result['Initial Fitness']:.6f}\\n\")\n",
    "        f.write(f\"Initial RMSE: {best_result['Initial RMSE']:.6f}\\n\")\n",
    "        f.write(f\"Final Fitness: {best_result['Final Fitness']:.6f}\\n\")\n",
    "        f.write(f\"Final RMSE: {best_result['Final RMSE']:.6f}\\n\")\n",
    "        f.write(f\"Transformation Error: {best_result['Transform Error']:.6f}\\n\")\n",
    "        f.write(f\"Runtime: {best_result['Runtime (s)']:.6f} seconds\\n\\n\")\n",
    "        \n",
    "        # Get the best experiment's transformation matrix\n",
    "        best_exp_result = next(r for r in results if r['experiment_name'] == best_result['Experiment'])\n",
    "        \n",
    "        f.write(\"Best Estimated Transformation Matrix:\\n\")\n",
    "        f.write(format_transformation_matrix(best_exp_result['transformation_matrix']))\n",
    "    \n",
    "    print(f\"\\nAll experiment results saved to {output_dir}\")\n",
    "    print(f\"Best experiment: {best_result['Experiment']} with RMSE: {best_result['Final RMSE']:.6f}\")\n",
    "    display(results_df)\n",
    "    return results, results_df\n",
    "\n",
    "def main():\n",
    "    # Path to the dataset\n",
    "    dataset_path = \"selected_pcds\"  # Update this with your actual path\n",
    "    \n",
    "    try:\n",
    "        # Find all PCD files\n",
    "        pcd_files = find_available_pcds(dataset_path)\n",
    "        \n",
    "        # Find two consecutive valid PCD files\n",
    "        source, target, source_file, target_file = find_consecutive_valid_pcds(pcd_files)\n",
    "        \n",
    "        print(f\"\\nUsing files for registration:\")\n",
    "        print(f\"Source: {source_file}\")\n",
    "        print(f\"Target: {target_file}\")\n",
    "        \n",
    "        # Run multiple experiments\n",
    "        results, results_df = run_multiple_experiments(source, target, source_file, target_file)\n",
    "        \n",
    "        # Create visualizations for comparison\n",
    "        output_dir = \"experiment_results\"\n",
    "        \n",
    "        # Create a bar chart for final RMSE\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        results_df_plot = results_df.sort_values('Experiment')  # Sort for consistent ordering\n",
    "        plt.bar(results_df_plot['Experiment'], results_df_plot['Final RMSE'])\n",
    "        plt.title('Final RMSE by Experiment')\n",
    "        plt.xlabel('Experiment')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"rmse_comparison.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Create a bar chart for fitness\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.bar(results_df_plot['Experiment'], results_df_plot['Final Fitness'])\n",
    "        plt.title('Final Fitness by Experiment')\n",
    "        plt.xlabel('Experiment')\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"fitness_comparison.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot initial vs final RMSE\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bar_width = 0.35\n",
    "        r1 = np.arange(len(results_df_plot))\n",
    "        r2 = [x + bar_width for x in r1]\n",
    "        plt.bar(r1, results_df_plot['Initial RMSE'], width=bar_width, label='Initial RMSE')\n",
    "        plt.bar(r2, results_df_plot['Final RMSE'], width=bar_width, label='Final RMSE')\n",
    "        plt.xlabel('Experiment')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title('Initial vs Final RMSE')\n",
    "        plt.xticks([r + bar_width/2 for r in r1], results_df_plot['Experiment'], rotation=45, ha='right')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"initial_vs_final_rmse.png\"), dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\nAll visualizations created successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded selected_pcds/pointcloud_0000.pcd with 22915 points\n",
      "Loaded selected_pcds/pointcloud_0004.pcd with 22904 points\n",
      "Using best parameters: {'experiment_name': 'low_threshold', 'init_method': 'random', 'icp_method': 'point_to_point', 'voxel_size': 0.05, 'threshold': 0.02}\n",
      "ICP Registration Results:\n",
      "Fitness: 0.002872\n",
      "Inlier RMSE: 0.013079\n",
      "Error Statistics:\n",
      "Mean error: 1.046206 m\n",
      "Median error: 0.620559 m\n",
      "Max error: 14.951788 m\n",
      "Standard deviation: 1.322900 m\n",
      "Visualization results saved to part3_results\n",
      "Transformation analysis saved to part3_results/transformation_analysis.txt\n",
      "\n",
      "Transformation Summary:\n",
      "Rotation: 133.89 degrees\n",
      "Translation: 0.464904 meters\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "def load_best_params():\n",
    "    \"\"\"Load the best parameters from experiment results.\"\"\"\n",
    "    try:\n",
    "        # First try to load from the CSV file\n",
    "        results_file = \"experiment_results/experiment_results.csv\"\n",
    "        if os.path.exists(results_file):\n",
    "            results_df = pd.read_csv(results_file)\n",
    "            # Sort by Final RMSE (lower is better)\n",
    "            results_df = results_df.sort_values('Final RMSE')\n",
    "            best_exp = results_df.iloc[0]\n",
    "            \n",
    "            return {\n",
    "                'experiment_name': best_exp['Experiment'],\n",
    "                'init_method': best_exp['Init Method'],\n",
    "                'icp_method': best_exp['ICP Method'],\n",
    "                'voxel_size': best_exp['Voxel Size'],\n",
    "                'threshold': best_exp['Threshold']\n",
    "            }\n",
    "        else:\n",
    "            # If file doesn't exist, return default best params\n",
    "            print(\"Experiment results file not found. Using default best parameters.\")\n",
    "            return {\n",
    "                'experiment_name': 'default_best',\n",
    "                'init_method': 'random',\n",
    "                'icp_method': 'point_to_plane',\n",
    "                'voxel_size': 0.05,\n",
    "                'threshold': 0.05\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading best parameters: {e}\")\n",
    "        # Return default values\n",
    "        return {\n",
    "            'experiment_name': 'default_best',\n",
    "            'init_method': 'random',\n",
    "            'icp_method': 'point_to_plane',\n",
    "            'voxel_size': 0.05,\n",
    "            'threshold': 0.05\n",
    "        }\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Load a point cloud from a PCD file.\"\"\"\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(file_path)\n",
    "        if len(pcd.points) == 0:\n",
    "            print(f\"Warning: {file_path} loaded but contains 0 points\")\n",
    "            return None\n",
    "        print(f\"Loaded {file_path} with {len(pcd.points)} points\")\n",
    "        return pcd\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.05, compute_normals=True):\n",
    "    \"\"\"Downsample and compute normals for a point cloud.\"\"\"\n",
    "    # Downsample using voxel grid\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    # Estimate normals if needed (for point-to-plane ICP)\n",
    "    if compute_normals:\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    \n",
    "    return pcd_down\n",
    "\n",
    "def prepare_dataset(source_pcd, target_pcd, voxel_size=0.05, compute_normals=True):\n",
    "    \"\"\"Prepare point cloud data for registration.\"\"\"\n",
    "    source_down = preprocess_point_cloud(source_pcd, voxel_size, compute_normals)\n",
    "    target_down = preprocess_point_cloud(target_pcd, voxel_size, compute_normals)\n",
    "    \n",
    "    return source_down, target_down\n",
    "\n",
    "def get_initial_transformation(method=\"random\", source=None, target=None, voxel_size=0.05):\n",
    "    \"\"\"Get initial transformation based on specified method.\"\"\"\n",
    "    from scipy.stats import ortho_group\n",
    "    \n",
    "    if method == \"random\":\n",
    "        # Generate a random rotation matrix (3x3) from the orthogonal group\n",
    "        R = ortho_group.rvs(3)\n",
    "        \n",
    "        # Ensure it's a proper rotation matrix (det = 1)\n",
    "        if np.linalg.det(R) < 0:\n",
    "            R[:, 0] = -R[:, 0]  # Flip one column to ensure det = 1\n",
    "        \n",
    "        # Generate a small random translation\n",
    "        t = np.random.uniform(-0.5, 0.5, 3).reshape(3, 1)\n",
    "        \n",
    "        # Create the 4x4 transformation matrix\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = t.flatten()\n",
    "        \n",
    "        return T\n",
    "    elif method == \"identity\":\n",
    "        return np.eye(4)\n",
    "    elif method == \"ransac\":\n",
    "        # Use RANSAC for global registration\n",
    "        if source is None or target is None:\n",
    "            raise ValueError(\"Source and target point clouds are required for RANSAC initialization\")\n",
    "        \n",
    "        # Prepare FPFH feature descriptors\n",
    "        source_fpfh = compute_fpfh_features(source, voxel_size)\n",
    "        target_fpfh = compute_fpfh_features(target, voxel_size)\n",
    "        \n",
    "        # RANSAC registration\n",
    "        distance_threshold = voxel_size * 1.5\n",
    "        result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "            source, target, source_fpfh, target_fpfh, distance_threshold,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "            4,  # Number of points to use for RANSAC\n",
    "            [\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "                o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "            ],\n",
    "            o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 500)\n",
    "        )\n",
    "        return result.transformation\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown initialization method: {method}\")\n",
    "\n",
    "def compute_fpfh_features(pcd, voxel_size):\n",
    "    \"\"\"Compute FPFH features for a point cloud.\"\"\"\n",
    "    radius_normal = voxel_size * 2\n",
    "    radius_feature = voxel_size * 5\n",
    "    \n",
    "    # Ensure normals are computed\n",
    "    if not pcd.has_normals():\n",
    "        pcd.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    \n",
    "    # Compute FPFH features\n",
    "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    \n",
    "    return fpfh\n",
    "\n",
    "def perform_best_registration(source, target, best_params):\n",
    "    \"\"\"Register source to target using the best parameters.\"\"\"\n",
    "    # Prepare datasets\n",
    "    compute_normals = best_params['icp_method'] == 'point_to_plane'\n",
    "    source_down, target_down = prepare_dataset(source, target, best_params['voxel_size'], compute_normals)\n",
    "    \n",
    "    # Get initial transformation\n",
    "    initial_transformation = get_initial_transformation(\n",
    "        best_params['init_method'], source_down, target_down, best_params['voxel_size']\n",
    "    )\n",
    "    \n",
    "    # Set up ICP method\n",
    "    if best_params['icp_method'] == 'point_to_point':\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    elif best_params['icp_method'] == 'point_to_plane':\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ICP method: {best_params['icp_method']}\")\n",
    "    \n",
    "    # Execute ICP\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source_down, target_down, best_params['threshold'], initial_transformation,\n",
    "        estimation,\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100)\n",
    "    )\n",
    "    \n",
    "    print(f\"ICP Registration Results:\")\n",
    "    print(f\"Fitness: {result.fitness:.6f}\")\n",
    "    print(f\"Inlier RMSE: {result.inlier_rmse:.6f}\")\n",
    "    \n",
    "    return result.transformation\n",
    "\n",
    "def visualize_transformed_cloud(source, target, transformation, output_dir=\"part3_results\"):\n",
    "    \"\"\"Visualize and save the transformed point cloud compared to target.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Transform source\n",
    "    source_transformed = copy.deepcopy(source)\n",
    "    source_transformed.transform(transformation)\n",
    "    \n",
    "    # Visualize original clouds\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot original source and target\n",
    "    ax1 = fig.add_subplot(221, projection='3d')\n",
    "    source_points = np.asarray(source.points)\n",
    "    target_points = np.asarray(target.points)\n",
    "    \n",
    "    # Sample points for better visualization\n",
    "    max_points = 5000\n",
    "    source_indices = np.random.choice(len(source_points), min(max_points, len(source_points)), replace=False)\n",
    "    target_indices = np.random.choice(len(target_points), min(max_points, len(target_points)), replace=False)\n",
    "    \n",
    "    source_points = source_points[source_indices]\n",
    "    target_points = target_points[target_indices]\n",
    "    \n",
    "    ax1.scatter(source_points[:, 0], source_points[:, 1], source_points[:, 2], c='red', s=1, label='Source')\n",
    "    ax1.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    ax1.set_title('Original Point Clouds')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot transformed source and target\n",
    "    ax2 = fig.add_subplot(222, projection='3d')\n",
    "    transformed_points = np.asarray(source_transformed.points)[source_indices]\n",
    "    ax2.scatter(transformed_points[:, 0], transformed_points[:, 1], transformed_points[:, 2], c='green', s=1, label='Transformed Source')\n",
    "    ax2.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    ax2.set_title('Transformed Source and Target')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Plot side view\n",
    "    ax3 = fig.add_subplot(223, projection='3d')\n",
    "    ax3.scatter(source_points[:, 0], source_points[:, 1], source_points[:, 2], c='red', s=1, label='Source')\n",
    "    ax3.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    ax3.view_init(elev=0, azim=90)\n",
    "    ax3.set_title('Side View - Original')\n",
    "    \n",
    "    # Plot side view of transformed\n",
    "    ax4 = fig.add_subplot(224, projection='3d')\n",
    "    ax4.scatter(transformed_points[:, 0], transformed_points[:, 1], transformed_points[:, 2], c='green', s=1, label='Transformed Source')\n",
    "    ax4.scatter(target_points[:, 0], target_points[:, 1], target_points[:, 2], c='blue', s=1, label='Target')\n",
    "    ax4.view_init(elev=0, azim=90)\n",
    "    ax4.set_title('Side View - Transformed')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"transformed_visualization.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create a colored point cloud visualization\n",
    "    source_transformed.paint_uniform_color([1, 0, 0])  # Red\n",
    "    target.paint_uniform_color([0, 0, 1])  # Blue\n",
    "    \n",
    "    # Get downsampled versions for cleaner visualization\n",
    "    source_transformed_down = source_transformed.voxel_down_sample(0.05)\n",
    "    target_down = target.voxel_down_sample(0.05)\n",
    "    \n",
    "    # Save to PCD files\n",
    "    o3d.io.write_point_cloud(os.path.join(output_dir, \"source_transformed.pcd\"), source_transformed)\n",
    "    o3d.io.write_point_cloud(os.path.join(output_dir, \"target.pcd\"), target)\n",
    "    \n",
    "    # Save the transformation matrix\n",
    "    np.savetxt(os.path.join(output_dir, \"transformation_matrix.txt\"), transformation)\n",
    "    \n",
    "    # Generate error heatmap\n",
    "    generate_error_heatmap(source_transformed, target, os.path.join(output_dir, \"error_heatmap.png\"))\n",
    "    \n",
    "    print(f\"Visualization results saved to {output_dir}\")\n",
    "    \n",
    "    return source_transformed\n",
    "\n",
    "def generate_error_heatmap(source, target, output_file):\n",
    "    \"\"\"Generate a heatmap showing the error distance between source and target point clouds.\"\"\"\n",
    "    # Create a KD-tree from target points\n",
    "    target_tree = o3d.geometry.KDTreeFlann(target)\n",
    "    \n",
    "    # Compute distances from each source point to the nearest target point\n",
    "    source_points = np.asarray(source.points)\n",
    "    distances = []\n",
    "    \n",
    "    # Only use a subset of points for large point clouds\n",
    "    max_points = 10000\n",
    "    if len(source_points) > max_points:\n",
    "        indices = np.random.choice(len(source_points), max_points, replace=False)\n",
    "        source_points = source_points[indices]\n",
    "    \n",
    "    for point in source_points:\n",
    "        _, idx, dist = target_tree.search_knn_vector_3d(point, 1)\n",
    "        distances.append(np.sqrt(dist[0]))\n",
    "    \n",
    "    # Create a scatter plot with distance-based coloring\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Plot a 3D scatter with distances as colors\n",
    "    ax = plt.axes(projection='3d')\n",
    "    scatter = ax.scatter(\n",
    "        source_points[:, 0], source_points[:, 1], source_points[:, 2],\n",
    "        c=distances, \n",
    "        cmap='jet',\n",
    "        s=1,\n",
    "        vmin=0,\n",
    "        vmax=max(0.1, np.percentile(distances, 95))  # Cap for better visualization\n",
    "    )\n",
    "    \n",
    "    ax.set_title('Point Cloud Registration Error Heatmap')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    \n",
    "    # Add a color bar\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Distance to nearest point (m)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate and print error statistics\n",
    "    mean_error = np.mean(distances)\n",
    "    median_error = np.median(distances)\n",
    "    max_error = np.max(distances)\n",
    "    std_error = np.std(distances)\n",
    "    \n",
    "    print(f\"Error Statistics:\")\n",
    "    print(f\"Mean error: {mean_error:.6f} m\")\n",
    "    print(f\"Median error: {median_error:.6f} m\")\n",
    "    print(f\"Max error: {max_error:.6f} m\")\n",
    "    print(f\"Standard deviation: {std_error:.6f} m\")\n",
    "    \n",
    "    # Save error statistics\n",
    "    with open(output_file.replace(\".png\", \"_stats.txt\"), 'w') as f:\n",
    "        f.write(\"Point Cloud Registration Error Statistics\\n\")\n",
    "        f.write(\"=======================================\\n\\n\")\n",
    "        f.write(f\"Mean error: {mean_error:.6f} m\\n\")\n",
    "        f.write(f\"Median error: {median_error:.6f} m\\n\")\n",
    "        f.write(f\"Max error: {max_error:.6f} m\\n\")\n",
    "        f.write(f\"Standard deviation: {std_error:.6f} m\\n\")\n",
    "\n",
    "def analyze_transformation_matrix(transformation, output_file=\"part3_results/transformation_analysis.txt\"):\n",
    "    \"\"\"Analyze the transformation matrix to understand what it does.\"\"\"\n",
    "    # Extract rotation matrix and translation vector\n",
    "    rotation = transformation[:3, :3]\n",
    "    translation = transformation[:3, 3]\n",
    "    \n",
    "    # Check if rotation matrix is valid\n",
    "    det = np.linalg.det(rotation)\n",
    "    is_orthogonal = np.allclose(np.dot(rotation, rotation.T), np.eye(3), atol=1e-6)\n",
    "    \n",
    "    # Compute rotation angle\n",
    "    angle = np.arccos((np.trace(rotation) - 1) / 2)\n",
    "    angle_degrees = np.degrees(angle)\n",
    "    \n",
    "    # Compute rotation axis\n",
    "    if np.isclose(angle, 0) or np.isclose(angle, np.pi):\n",
    "        # For 0 or 180 degrees, axis may not be well-defined\n",
    "        rotation_axis = None\n",
    "    else:\n",
    "        # For other angles, compute axis as the eigenvector with eigenvalue 1\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(rotation)\n",
    "        for i in range(len(eigenvalues)):\n",
    "            if np.isclose(eigenvalues[i], 1.0):\n",
    "                rotation_axis = np.real(eigenvectors[:, i])\n",
    "                rotation_axis = rotation_axis / np.linalg.norm(rotation_axis)\n",
    "                break\n",
    "    \n",
    "    # Translation distance\n",
    "    translation_distance = np.linalg.norm(translation)\n",
    "    \n",
    "    # Write analysis to file\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"Transformation Matrix Analysis\\n\")\n",
    "        f.write(\"============================\\n\\n\")\n",
    "        \n",
    "        f.write(\"Transformation Matrix:\\n\")\n",
    "        for row in transformation:\n",
    "            f.write(f\"{row[0]:10.6f} {row[1]:10.6f} {row[2]:10.6f} {row[3]:10.6f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        f.write(f\"Rotation Matrix Determinant: {det:.6f}\\n\")\n",
    "        f.write(f\"Is Orthogonal: {is_orthogonal}\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Rotation Angle: {angle_degrees:.2f} degrees\\n\")\n",
    "        if rotation_axis is not None:\n",
    "            f.write(f\"Rotation Axis: [{rotation_axis[0]:.6f}, {rotation_axis[1]:.6f}, {rotation_axis[2]:.6f}]\\n\")\n",
    "        else:\n",
    "            f.write(\"Rotation Axis: Not well-defined (0 or 180 degrees rotation)\\n\")\n",
    "        \n",
    "        f.write(f\"\\nTranslation Vector: [{translation[0]:.6f}, {translation[1]:.6f}, {translation[2]:.6f}]\\n\")\n",
    "        f.write(f\"Translation Distance: {translation_distance:.6f} meters\\n\")\n",
    "        \n",
    "        f.write(\"\\nInterpretation:\\n\")\n",
    "        f.write(f\"The transformation represents a rotation of {angle_degrees:.2f} degrees \")\n",
    "        if rotation_axis is not None:\n",
    "            f.write(f\"around the axis [{rotation_axis[0]:.4f}, {rotation_axis[1]:.4f}, {rotation_axis[2]:.4f}], \")\n",
    "        f.write(f\"followed by a translation of {translation_distance:.4f} meters in the direction \")\n",
    "        f.write(f\"[{translation[0]/translation_distance:.4f}, {translation[1]/translation_distance:.4f}, {translation[2]/translation_distance:.4f}].\\n\")\n",
    "        \n",
    "        f.write(\"\\nThis represents the movement of the TurtleBot between the two consecutive scans.\\n\")\n",
    "    \n",
    "    print(f\"Transformation analysis saved to {output_file}\")\n",
    "    \n",
    "    # Print summary to console\n",
    "    print(\"\\nTransformation Summary:\")\n",
    "    print(f\"Rotation: {angle_degrees:.2f} degrees\")\n",
    "    print(f\"Translation: {translation_distance:.6f} meters\")\n",
    "    \n",
    "    return {\n",
    "        'rotation_angle': angle_degrees,\n",
    "        'translation_distance': translation_distance,\n",
    "        'rotation_axis': rotation_axis,\n",
    "        'translation_vector': translation\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function for part 3.\"\"\"\n",
    "    # Set paths\n",
    "    dataset_path = \"selected_pcds\"  # Update with your path\n",
    "    source_file = \"selected_pcds/pointcloud_0000.pcd\"  # From previous output\n",
    "    target_file = \"selected_pcds/pointcloud_0004.pcd\"  # From previous output\n",
    "    output_dir = \"part3_results\"\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load point clouds\n",
    "    source = load_point_cloud(source_file)\n",
    "    target = load_point_cloud(target_file)\n",
    "    \n",
    "    if source is None or target is None:\n",
    "        print(\"Failed to load point clouds. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Load best parameters\n",
    "    best_params = load_best_params()\n",
    "    print(f\"Using best parameters: {best_params}\")\n",
    "    \n",
    "    # Perform registration with best parameters\n",
    "    transformation = perform_best_registration(source, target, best_params)\n",
    "    \n",
    "    # Visualize transformed point cloud\n",
    "    source_transformed = visualize_transformed_cloud(source, target, transformation, output_dir)\n",
    "    \n",
    "    # Analyze transformation matrix\n",
    "    transformation_analysis = analyze_transformation_matrix(transformation, os.path.join(output_dir, \"transformation_analysis.txt\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 PCD files.\n",
      "Registering point clouds...\n",
      "Processing 1/99: pointcloud_0004.pcd\n",
      "Processing 2/99: pointcloud_0008.pcd\n",
      "Processing 3/99: pointcloud_0012.pcd\n",
      "Processing 4/99: pointcloud_0016.pcd\n",
      "Processing 5/99: pointcloud_0020.pcd\n",
      "Processing 6/99: pointcloud_0024.pcd\n",
      "Processing 7/99: pointcloud_0028.pcd\n",
      "Processing 8/99: pointcloud_0032.pcd\n",
      "Processing 9/99: pointcloud_0036.pcd\n",
      "Processing 10/99: pointcloud_0040.pcd\n",
      "Processing 11/99: pointcloud_0044.pcd\n",
      "Processing 12/99: pointcloud_0048.pcd\n",
      "Processing 13/99: pointcloud_0052.pcd\n",
      "Processing 14/99: pointcloud_0056.pcd\n",
      "Processing 15/99: pointcloud_0060.pcd\n",
      "Processing 16/99: pointcloud_0064.pcd\n",
      "Processing 17/99: pointcloud_0068.pcd\n",
      "Processing 18/99: pointcloud_0072.pcd\n",
      "Processing 19/99: pointcloud_0076.pcd\n",
      "Processing 20/99: pointcloud_0080.pcd\n",
      "Processing 21/99: pointcloud_0084.pcd\n",
      "Processing 22/99: pointcloud_0088.pcd\n",
      "Processing 23/99: pointcloud_0092.pcd\n",
      "Processing 24/99: pointcloud_0096.pcd\n",
      "Processing 25/99: pointcloud_0100.pcd\n",
      "Processing 26/99: pointcloud_0104.pcd\n",
      "Processing 27/99: pointcloud_0108.pcd\n",
      "Processing 28/99: pointcloud_0112.pcd\n",
      "Processing 29/99: pointcloud_0116.pcd\n",
      "Processing 30/99: pointcloud_0120.pcd\n",
      "Processing 31/99: pointcloud_0124.pcd\n",
      "Processing 32/99: pointcloud_0128.pcd\n",
      "Processing 33/99: pointcloud_0132.pcd\n",
      "Processing 34/99: pointcloud_0136.pcd\n",
      "Processing 35/99: pointcloud_0140.pcd\n",
      "Processing 36/99: pointcloud_0144.pcd\n",
      "Processing 37/99: pointcloud_0148.pcd\n",
      "Processing 38/99: pointcloud_0152.pcd\n",
      "Processing 39/99: pointcloud_0156.pcd\n",
      "Processing 40/99: pointcloud_0160.pcd\n",
      "Processing 41/99: pointcloud_0164.pcd\n",
      "Processing 42/99: pointcloud_0168.pcd\n",
      "Processing 43/99: pointcloud_0172.pcd\n",
      "Processing 44/99: pointcloud_0176.pcd\n",
      "Processing 45/99: pointcloud_0180.pcd\n",
      "Processing 46/99: pointcloud_0184.pcd\n",
      "Processing 47/99: pointcloud_0188.pcd\n",
      "Processing 48/99: pointcloud_0192.pcd\n",
      "Processing 49/99: pointcloud_0196.pcd\n",
      "Processing 50/99: pointcloud_0200.pcd\n",
      "Processing 51/99: pointcloud_0204.pcd\n",
      "Processing 52/99: pointcloud_0208.pcd\n",
      "Processing 53/99: pointcloud_0212.pcd\n",
      "Processing 54/99: pointcloud_0216.pcd\n",
      "Processing 55/99: pointcloud_0220.pcd\n",
      "Processing 56/99: pointcloud_0224.pcd\n",
      "Processing 57/99: pointcloud_0228.pcd\n",
      "Processing 58/99: pointcloud_0232.pcd\n",
      "Processing 59/99: pointcloud_0236.pcd\n",
      "Processing 60/99: pointcloud_0240.pcd\n",
      "Processing 61/99: pointcloud_0244.pcd\n",
      "Processing 62/99: pointcloud_0248.pcd\n",
      "Processing 63/99: pointcloud_0252.pcd\n",
      "Processing 64/99: pointcloud_0256.pcd\n",
      "Processing 65/99: pointcloud_0260.pcd\n",
      "Processing 66/99: pointcloud_0264.pcd\n",
      "Processing 67/99: pointcloud_0268.pcd\n",
      "Processing 68/99: pointcloud_0272.pcd\n",
      "Processing 69/99: pointcloud_0276.pcd\n",
      "Processing 70/99: pointcloud_0280.pcd\n",
      "Processing 71/99: pointcloud_0284.pcd\n",
      "Processing 72/99: pointcloud_0288.pcd\n",
      "Processing 73/99: pointcloud_0292.pcd\n",
      "Processing 74/99: pointcloud_0296.pcd\n",
      "Processing 75/99: pointcloud_0300.pcd\n",
      "Processing 76/99: pointcloud_0304.pcd\n",
      "Processing 77/99: pointcloud_0308.pcd\n",
      "Processing 78/99: pointcloud_0312.pcd\n",
      "Processing 79/99: pointcloud_0316.pcd\n",
      "Processing 80/99: pointcloud_0320.pcd\n",
      "Processing 81/99: pointcloud_0324.pcd\n",
      "Processing 82/99: pointcloud_0328.pcd\n",
      "Processing 83/99: pointcloud_0332.pcd\n",
      "Processing 84/99: pointcloud_0336.pcd\n",
      "Processing 85/99: pointcloud_0340.pcd\n",
      "Processing 86/99: pointcloud_0344.pcd\n",
      "Processing 87/99: pointcloud_0348.pcd\n",
      "Processing 88/99: pointcloud_0352.pcd\n",
      "Processing 89/99: pointcloud_0356.pcd\n",
      "Processing 90/99: pointcloud_0360.pcd\n",
      "Processing 91/99: pointcloud_0364.pcd\n",
      "Processing 92/99: pointcloud_0368.pcd\n",
      "Processing 93/99: pointcloud_0372.pcd\n",
      "Processing 94/99: pointcloud_0376.pcd\n",
      "Processing 95/99: pointcloud_0380.pcd\n",
      "Processing 96/99: pointcloud_0384.pcd\n",
      "Processing 97/99: pointcloud_0388.pcd\n",
      "Processing 98/99: pointcloud_0392.pcd\n",
      "Processing 99/99: pointcloud_0396.pcd\n",
      "\n",
      "Registration Summary:\n",
      "Average Fitness: 0.945028\n",
      "Average Inlier RMSE: 0.018723\n",
      "Total Trajectory Length: 100 points\n",
      "\n",
      "Visualizing results...\n",
      "Downsampled point cloud to 120085 points for visualization\n",
      "Visualization results saved to part4_results/ directory\n",
      "\n",
      "All results saved to part4_results/ directory\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def find_all_point_clouds(dataset_path):\n",
    "    \"\"\"Find all PCD files in the dataset folder.\"\"\"\n",
    "    pcd_files = glob.glob(os.path.join(dataset_path, \"pointcloud_*.pcd\"))\n",
    "    \n",
    "    # Sort files by their index number\n",
    "    def extract_number(filename):\n",
    "        match = re.search(r'pointcloud_(\\d+)\\.pcd', filename)\n",
    "        return int(match.group(1)) if match else -1\n",
    "    \n",
    "    pcd_files.sort(key=extract_number)\n",
    "    \n",
    "    if len(pcd_files) < 2:\n",
    "        raise ValueError(\"Not enough PCD files found in the dataset folder. Need at least 2 files.\")\n",
    "    \n",
    "    print(f\"Found {len(pcd_files)} PCD files.\")\n",
    "    return pcd_files\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Load a point cloud from a PCD file.\"\"\"\n",
    "    try:\n",
    "        pcd = o3d.io.read_point_cloud(file_path)\n",
    "        if len(pcd.points) == 0:\n",
    "            print(f\"Warning: {file_path} loaded but contains 0 points\")\n",
    "            return None\n",
    "        return pcd\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size=0.05, compute_normals=True):\n",
    "    \"\"\"Downsample and compute normals for a point cloud.\"\"\"\n",
    "    # Downsample using voxel grid\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    # Estimate normals if needed (for point-to-plane ICP)\n",
    "    if compute_normals:\n",
    "        pcd_down.estimate_normals(\n",
    "            search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
    "    \n",
    "    return pcd_down\n",
    "\n",
    "def register_point_clouds(source, target, voxel_size=0.05, icp_method=\"point_to_point\", \n",
    "                         threshold=0.05, max_iteration=100):\n",
    "    \"\"\"Register source to target point cloud.\"\"\"\n",
    "    # Determine if normals are needed\n",
    "    compute_normals = icp_method == \"point_to_plane\"\n",
    "    \n",
    "    # Preprocess point clouds\n",
    "    source_down = preprocess_point_cloud(source, voxel_size, compute_normals)\n",
    "    target_down = preprocess_point_cloud(target, voxel_size, compute_normals)\n",
    "    \n",
    "    # Get initial transformation (identity)\n",
    "    initial_transformation = np.eye(4)\n",
    "    \n",
    "    # Set up ICP method\n",
    "    if icp_method == \"point_to_point\":\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    elif icp_method == \"point_to_plane\":\n",
    "        estimation = o3d.pipelines.registration.TransformationEstimationPointToPlane()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ICP method: {icp_method}\")\n",
    "    \n",
    "    # Execute ICP\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source_down, target_down, threshold, initial_transformation,\n",
    "        estimation,\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=max_iteration)\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def register_sequential_point_clouds(pcd_files, voxel_size=0.05, icp_method=\"point_to_point\", \n",
    "                                    threshold=0.05, max_iteration=100):\n",
    "    \"\"\"Register all point clouds sequentially.\"\"\"\n",
    "    # Load first point cloud\n",
    "    pcds = []\n",
    "    first_cloud = load_point_cloud(pcd_files[0])\n",
    "    if first_cloud is None:\n",
    "        raise ValueError(f\"Could not load first point cloud: {pcd_files[0]}\")\n",
    "    \n",
    "    pcds.append(first_cloud)\n",
    "    \n",
    "    # Global transformation list\n",
    "    transformations = [np.eye(4)]  # First cloud has identity transformation\n",
    "    \n",
    "    # Position list for trajectory\n",
    "    positions = [[0, 0, 0]]  # First position is origin\n",
    "    \n",
    "    # Results of pairwise registration\n",
    "    pairwise_results = []\n",
    "    \n",
    "    # Log file for registration results\n",
    "    os.makedirs(\"part4_results\", exist_ok=True)\n",
    "    with open(\"part4_results/registration_log.txt\", \"w\") as log_file:\n",
    "        log_file.write(\"Point Cloud Registration Log\\n\")\n",
    "        log_file.write(\"==========================\\n\\n\")\n",
    "        \n",
    "        # Register consecutive point clouds\n",
    "        for i in range(1, len(pcd_files)):\n",
    "            file_path = pcd_files[i]\n",
    "            print(f\"Processing {i}/{len(pcd_files)-1}: {os.path.basename(file_path)}\")\n",
    "            \n",
    "            # Load current point cloud\n",
    "            current_cloud = load_point_cloud(file_path)\n",
    "            if current_cloud is None:\n",
    "                print(f\"Skipping {file_path} due to loading error\")\n",
    "                continue\n",
    "            \n",
    "            # Register with previous cloud\n",
    "            registration_start = time.time()\n",
    "            result = register_point_clouds(\n",
    "                current_cloud, pcds[-1], \n",
    "                voxel_size, icp_method, \n",
    "                threshold, max_iteration\n",
    "            )\n",
    "            registration_time = time.time() - registration_start\n",
    "            \n",
    "            # Compute transformation relative to first cloud\n",
    "            # Current = Previous * Transformation^(-1)\n",
    "            # We invert because we register current to previous, but want to transform from first to current\n",
    "            relative_transform = np.linalg.inv(result.transformation)\n",
    "            global_transform = np.dot(transformations[-1], relative_transform)\n",
    "            \n",
    "            # Store results\n",
    "            transformations.append(global_transform)\n",
    "            \n",
    "            # Extract position (translation part of the transformation)\n",
    "            position = global_transform[:3, 3].tolist()\n",
    "            positions.append(position)\n",
    "            \n",
    "            # Add transformed point cloud to list\n",
    "            transformed_cloud = copy.deepcopy(current_cloud)\n",
    "            transformed_cloud.transform(global_transform)\n",
    "            pcds.append(transformed_cloud)\n",
    "            \n",
    "            # Store and log registration details\n",
    "            pairwise_result = {\n",
    "                'source': os.path.basename(file_path),\n",
    "                'target': os.path.basename(pcd_files[i-1]),\n",
    "                'fitness': result.fitness,\n",
    "                'inlier_rmse': result.inlier_rmse,\n",
    "                'registration_time': registration_time,\n",
    "                'transformation': result.transformation,\n",
    "                'global_transformation': global_transform,\n",
    "                'position': position\n",
    "            }\n",
    "            pairwise_results.append(pairwise_result)\n",
    "            \n",
    "            # Write to log\n",
    "            log_file.write(f\"Pair {i-1} to {i}: {os.path.basename(pcd_files[i-1])} -> {os.path.basename(file_path)}\\n\")\n",
    "            log_file.write(f\"Fitness: {result.fitness:.6f}\\n\")\n",
    "            log_file.write(f\"Inlier RMSE: {result.inlier_rmse:.6f}\\n\")\n",
    "            log_file.write(f\"Registration time: {registration_time:.6f} seconds\\n\")\n",
    "            log_file.write(f\"Position: [{position[0]:.6f}, {position[1]:.6f}, {position[2]:.6f}]\\n\")\n",
    "            log_file.write(f\"Transformation Matrix:\\n\")\n",
    "            for row in global_transform:\n",
    "                log_file.write(f\"{row[0]:10.6f} {row[1]:10.6f} {row[2]:10.6f} {row[3]:10.6f}\\n\")\n",
    "            log_file.write(\"\\n\")\n",
    "    \n",
    "    # Save trajectory to CSV\n",
    "    trajectory_df = pd.DataFrame(positions, columns=['x', 'y', 'z'])\n",
    "    trajectory_df.to_csv(\"part4_results/trajectory.csv\", index=False)\n",
    "    \n",
    "    return pcds, transformations, trajectory_df, pairwise_results\n",
    "\n",
    "def visualize_registration_results(pcds, trajectory_df):\n",
    "    \"\"\"Visualize the registration results without requiring a display.\"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(\"part4_results\", exist_ok=True)\n",
    "    \n",
    "    # 1. Visualize the trajectory in 3D\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(trajectory_df['x'], trajectory_df['y'], trajectory_df['z'], 'r-', linewidth=2)\n",
    "    ax.scatter(trajectory_df['x'], trajectory_df['y'], trajectory_df['z'], c='blue')\n",
    "    \n",
    "    # Add point indices\n",
    "    for i, (x, y, z) in enumerate(zip(trajectory_df['x'], trajectory_df['y'], trajectory_df['z'])):\n",
    "        if i % 5 == 0 or i == len(trajectory_df) - 1:  # Label every 5th point and the last point\n",
    "            ax.text(x, y, z, f'{i}', fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('X (m)')\n",
    "    ax.set_ylabel('Y (m)')\n",
    "    ax.set_zlabel('Z (m)')\n",
    "    ax.set_title('TurtleBot 3D Trajectory')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"part4_results/trajectory_3d.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Visualize the trajectory in 2D (top-down view)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(trajectory_df['x'], trajectory_df['y'], 'r-', linewidth=2)\n",
    "    plt.scatter(trajectory_df['x'], trajectory_df['y'], c='blue')\n",
    "    \n",
    "    # Add point indices\n",
    "    for i, (x, y) in enumerate(zip(trajectory_df['x'], trajectory_df['y'])):\n",
    "        if i % 5 == 0 or i == len(trajectory_df) - 1:  # Label every 5th point and the last point\n",
    "            plt.text(x, y, f'{i}', fontsize=9)\n",
    "    \n",
    "    plt.xlabel('X (m)')\n",
    "    plt.ylabel('Y (m)')\n",
    "    plt.title('TurtleBot 2D Trajectory (Top-Down View)')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"part4_results/trajectory_2d.png\", dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Save the combined point cloud to file without visualizing\n",
    "    combined_cloud = o3d.geometry.PointCloud()\n",
    "    for pcd in pcds:\n",
    "        combined_cloud += pcd\n",
    "    \n",
    "    # Save the combined point cloud to PCD file\n",
    "    o3d.io.write_point_cloud(\"part4_results/combined_point_cloud.pcd\", combined_cloud)\n",
    "    \n",
    "    # Create a simple visualization of the point cloud as colored points\n",
    "    points = np.asarray(combined_cloud.points)\n",
    "    \n",
    "    # If the point cloud is too large, downsample for visualization\n",
    "    if len(points) > 1000000:\n",
    "        # Use voxel downsampling to reduce size\n",
    "        combined_cloud = combined_cloud.voxel_down_sample(voxel_size=0.1)\n",
    "        points = np.asarray(combined_cloud.points)\n",
    "        print(f\"Downsampled point cloud to {len(points)} points for visualization\")\n",
    "    \n",
    "    # Create a scatter plot of points with fixed colors\n",
    "    if len(points) > 0:\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # Use x coordinate for coloring (just for visualization)\n",
    "        colors = points[:, 0]\n",
    "        p = ax.scatter(points[:, 0], points[:, 1], points[:, 2], \n",
    "                      c=colors, cmap='viridis', s=0.5)\n",
    "        \n",
    "        ax.set_xlabel('X (m)')\n",
    "        ax.set_ylabel('Y (m)')\n",
    "        ax.set_zlabel('Z (m)')\n",
    "        ax.set_title('Combined Point Cloud')\n",
    "        \n",
    "        # Add a color bar\n",
    "        fig.colorbar(p, ax=ax, label='X coordinate (m)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"part4_results/combined_point_cloud.png\", dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Visualization results saved to part4_results/ directory\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the point cloud registration pipeline.\"\"\"\n",
    "    # Configuration\n",
    "    dataset_path = \"selected_pcds\"  # Adjust path as needed\n",
    "    voxel_size = 0.05         # Adjust based on your best hyperparameters from part 2\n",
    "    icp_method = \"point_to_point\"  # As required by the assignment\n",
    "    threshold = 0.05          # Adjust based on your best hyperparameters from part 2\n",
    "    max_iteration = 100       # Adjust based on your best hyperparameters from part 2\n",
    "    \n",
    "    # Find all point cloud files\n",
    "    pcd_files = find_all_point_clouds(dataset_path)\n",
    "    \n",
    "    # Register all point clouds sequentially\n",
    "    print(\"Registering point clouds...\")\n",
    "    pcds, transformations, trajectory_df, pairwise_results = register_sequential_point_clouds(\n",
    "        pcd_files, voxel_size, icp_method, threshold, max_iteration\n",
    "    )\n",
    "    \n",
    "    # Summarize registration results\n",
    "    fitness_values = [result['fitness'] for result in pairwise_results]\n",
    "    rmse_values = [result['inlier_rmse'] for result in pairwise_results]\n",
    "    \n",
    "    print(\"\\nRegistration Summary:\")\n",
    "    print(f\"Average Fitness: {np.mean(fitness_values):.6f}\")\n",
    "    print(f\"Average Inlier RMSE: {np.mean(rmse_values):.6f}\")\n",
    "    print(f\"Total Trajectory Length: {len(pcds)} points\")\n",
    "    \n",
    "    # Create summary CSV\n",
    "    summary_df = pd.DataFrame(pairwise_results)\n",
    "    summary_df['source_index'] = range(1, len(pcd_files))\n",
    "    summary_df['target_index'] = range(0, len(pcd_files)-1)\n",
    "    \n",
    "    # Select relevant columns for CSV\n",
    "    summary_csv = summary_df[['source_index', 'target_index', 'fitness', 'inlier_rmse', 'registration_time']]\n",
    "    summary_csv.to_csv(\"part4_results/registration_summary.csv\", index=False)\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"\\nVisualizing results...\")\n",
    "    visualize_registration_results(pcds, trajectory_df)\n",
    "    \n",
    "    print(\"\\nAll results saved to part4_results/ directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samridh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
